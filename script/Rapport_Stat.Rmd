---
date: "28/03/2020"
output: html_document
---

<div>
<img src="https://media.licdn.com/dms/image/C560BAQHUCPLKiBDG3w/company-logo_200_200/0?e=2159024400&v=beta&t=oyn1hcdUk9NXqcdZgb_kIhABmIAiniK5pE4onmVdhFM" width=18%" align="left"/>

<img src="https://www.businessdecision.fr/uploads/Image/b8/IMF_ACCROCHE/GAB_BDFRANCE/8178_919_Keyviz-carre.jpg" width=20% align="right" />
</div>
<br /><br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
<div>
<center> <h1>Master2 MEDAS - USID17 - Statistiques - Faits stylisés du hasard</h1> </center>
</div>

\n<br />
\n<br />

<div align="center">
<img src="https://mrmint.fr/wp-content/uploads/2017/09/logistic-regression-model.png" width=50%/>
</div>

\n<br />
\n<br />

<center>**Groupe :** É.Guilmin & M.Chauveau </center>

\n<br />
\n<br />

<center>**Jury :** Erwan Josse </center>

<center>**Responsable Pédagogique :** X.Aimé  </center>

\n<br />
\n<br />

<center>**Établissement :** Cnam - Pays de la Loire - Nantes </center>

<center>**Formation :** Master Mégadonnées et Analyse Sociale </center>

\n<br />
\n<br />

```{r setup, include=FALSE}
install.packages('pacman')

pacman::p_load('tidyr')
pacman::p_load('dplyr')

#ggplot pour les représentations graphiques
pacman::p_load('ggplot2')
pacman::p_load('plotly')

# MASS pour la fonction stepAIC
pacman::p_load('MASS')

#
pacman::p_load('questionr')

# pour fonction sample.split
pacman::p_load('caTools')

pacman::p_load('knitr')

#Matrice de corrélation
pacman::p_load('corrplot')

#Représentation graphique du modèle
pacman::p_load('forestmodel')

#Représentation graphique des effets
pacman::p_load('labelled')
pacman::p_load('ggeffects')
pacman::p_load('cowplot')
pacman::p_load('effects')

# Courbe ROC
pacman::p_load('ROCR')

#Distance de Cook
pacman::p_load('car')
```


```{r chargement des données}
load(file='C:/Users/mchauveau/Documents/Maxime Chauveau/Master Medas/Projet_Stat/data/dataClean.RData')
```


\n<br />
\n<br />

<center> <h1>Présentation du sujet</h1> </center>

\n<br />
\n<br />


Pour ce projet, nous avons choisi le sujet suivant : Prédiciton des maladies cardiaques.

https://www.kaggle.com/dileep070/heart-disease-prediction-using-logistic-regression

Pour ce faire, nous avons préalablement préparé nos données, le scritp est disponible ici : ./script/data_prep.R

Ici nous verrons notre méthodologie de travail. 


<center> <h1>Statistique bivarivée</h1> </center>

Afin de mieux comprendre notre base de données, nous avons décidé de faire une étude descriptive.


```{r}
freq(df_heart$estMalade10)
```

Notre base comporte 3656 patients, dans laquelle 15 % des patients ont eu une maladie cardiovasculaire dans les 10 années suivants les prises de mesures. Ces données proviennt de la ville de Framingham dans le Massachusetts, aux États-Unis.

```{r Analyse par BPM}

fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$BPM[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$BPM[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par Sexe}

fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$Sexe[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$Sexe[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par Education}

fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$education[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$education[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par Fumeur à remplacer par un camembert}

fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$Fumeur[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$Fumeur[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par NbCigarrette_Jour faire des classes}

fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$NbCigarrete_Jour[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$NbCigarrete_Jour[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par MedPA}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$MedPA[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$MedPA[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par AVC}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$AVC[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$AVC[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par Hypertension}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$Hypertension[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$Hypertension[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par diabetes}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$diabetes[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$diabetes[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par TauxChol}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$TauxChol[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$TauxChol[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par sysTA}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$sysTA[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$sysTA[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```



```{r Analyse par diaTA}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$diaTA[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$diaTA[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par IMC}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$IMC[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$IMC[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par BPM}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$BPM[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$BPM[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par glucose}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$glucose[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$glucose[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


<center> <h1>Matrice de corrélation</h1> </center>

```{r}
mcor <- cor(df_correlation)
corrplot(mcor, type="upper", order="hclust", tl.col="black", tl.srt=45)
```

Les variables Fumeur et nbcigarrete_Jour sont très correlées : 0.77
diabetes glucose : 0.61
sysTA et diaTA : 0.79
Hypertention et sysTA : 0.70
Hypertension et diaTA : 0.62


<center> <h1>Régression logistique</h1> </center>


L'objectif de la régression logistique est de modéliser, de classifier, une variable binaire prenant ses valeurs dans {0,1} en fonction de variables explicatives quantitatives (et potentiellement qualitatives). La régression logistique est une méthode de classification (supervisée) qui permet de traiter des cas comme :

  - la prévision de présence/absence d'une maladie ;

  - la prévision de l'état de fonctionnement d'une machine-outil en fonction de ses caractéristiques (ancienneté, modèle, etc.), à des fins de maintenance prédictive ;

  - le credit scoring (attribution ou non d'un crédit).


Pour commencer nous allons faire une régression directement sur notre base de données.

```{r}
model_sature <- glm(estMalade10~. , data = df_heart, family = binomial)
summary(model_sature)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 6.

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


Une alternative à la fonction stepAIC est la fonction step qui fonctionne de la même manière. Cependant cela ne change rien aux régressions logistiques classiques.


```{r}
stepAIC(model_sature)
```


```{r}
var_label(df_heart$estMalade10) <- "Maladie dans les 10 Ans ?"
var_label(df_heart$Sexe) <- "Sexe"
var_label(df_heart$NbCigarrete_Jour) <- "Nombre de cigarette par jour"
var_label(df_heart$AVC) <- "AVC"
var_label(df_heart$Hypertension) <- "Hypertension"
var_label(df_heart$TauxChol) <- "Taux de Cholesterol"
var_label(df_heart$glucose) <- "Taux de glucose"
```


La fonction stepAIC nous donne le meilleur modèle qui est le suivant :

```{r}
modele_retenu <- glm(formula = estMalade10 ~ Sexe + age + NbCigarrete_Jour + AVC + 
    Hypertension + TauxChol + sysTA + glucose, family = binomial, 
    data = df_heart)
print(modele_retenu)
```


Tout d'abord, nous pouvons observer que la fonction stepAIC a sélectionné 8 variables.
Sexe
age
NbCigarrete_Jour
AVC
Hypertension
TauxChol
sysTA
glucose


Avec ce modèle nous avons un AIC de 2775. Pour rappel, l'AIC est le critère d'information d'Akaike, (en anglais Akaike information criterion ou AIC). C'est une mesure de la qualité d'un modèle statistique proposée par Hirotugu Akaike en 1973.

Lorsque l'on estime un modèle statistique, il est possible d'augmenter la vraisemblance du modèle en ajoutant un paramètre. Le critère d'information d'Akaike, tout comme le critère d'information bayésien, permet de pénaliser les modèles en fonction du nombre de paramètres afin de satisfaire le critère de parcimonie. On choisit alors le modèle avec le critère d'information d'Akaike le plus faible.


Interprétation

Nous avons donc un AIC de 2775.
Une déviance de  2757.

Elle compare la vraisemblance obtenue à celle d’un modèle de référence : le modèle complet (ou modèle saturé).

```{r}
exp(cbind(coef(modele_retenu), confint(modele_retenu)))
```


```{r}
forest_model(modele_retenu)
```


```{r}
plot(ggeffect(modele_retenu, "Sexe"))
```


```{r}
plot(ggeffect(modele_retenu, "age"))
```

```{r}
plot(ggeffect(modele_retenu, "NbCigarrete_Jour"))
```

```{r}
plot(ggeffect(modele_retenu, "AVC"))
```

```{r}
plot(ggeffect(modele_retenu, "Hypertension"))
```

```{r}
plot(ggeffect(modele_retenu, "TauxChol"))
```

```{r}
plot(ggeffect(modele_retenu, "sysTA"))
```

```{r}
plot(ggeffect(modele_retenu, "glucose"))
```


<center> <h1>Matrice de confusion</h1> </center>


```{r}
heart_pred <- predict(modele_retenu, type = "response", newdata = df_heart)
table(heart_pred > 0.5, df_heart$estMalade10)
```

Nous avons donc 530 (512+18) prédictions incorrectes sur un total de 3656, soit un taux de mauvais classement de 14,4 %.


TEST AVEC LES BASES TRAIN ET TEST


```{r}
model_sature <- glm(estMalade10~. , data = dfApprentissage1, family = binomial)
summary(model_sature)
```


```{r}
stepAIC(model_sature)
```



```{r}
modele_retenu <- glm(formula = estMalade10 ~ Sexe + age + NbCigarrete_Jour + TauxChol + 
    sysTA + BPM + glucose, family = binomial, data = dfApprentissage1)
print(modele_retenu)
```


```{r}
heart_pred <- predict(modele_retenu, type = "response", newdata = dftest1)
table(heart_pred > 0.5, dftest1$estMalade10)
```


Nous avons donc 180 (176+4) prédictions incorrectes sur un total de 1230, soit un taux de mauvais classement de 14.6 %.




<center> <h1>Étude des varibles les plus influentes</h1> </center>




```{r}
exp(cbind(coef(modele_retenu), confint(modele_retenu)))
```


```{r}
forest_model(modele_retenu)
```


```{r}
plot(ggeffect(modele_retenu, "Sexe"))
```


```{r}
plot(ggeffect(modele_retenu, "age"))
```

```{r}
plot(ggeffect(modele_retenu, "NbCigarrete_Jour"))
```

```{r}
plot(ggeffect(modele_retenu, "AVC"))
```

```{r}
plot(ggeffect(modele_retenu, "Hypertension"))
```

```{r}
plot(ggeffect(modele_retenu, "TauxChol"))
```

```{r}
plot(ggeffect(modele_retenu, "sysTA"))
```

```{r}
plot(ggeffect(modele_retenu, "glucose"))
```








<center> <h1>Courbe de ROC</h1> </center>

Courbe ROC : Receiver Operating Characteristic Curve, en français "Courbe caractéristique de fonctionnement du récepteur", à l'origine elle a été créée pour établir des signaux radios.

```{r}
pred <- prediction(heart_pred, dftest1$estMalade10)
perf <- performance(pred, "tpr", "fpr")
plot(perf)
```


```{r}

# Analyse des résidus
res_dev <- residuals(modele_retenu) #residus de deviance
res_pear <- residuals(modele_retenu, type = 'pearson') #residus de Pearson
res_dev_stand <- rstandard(modele_retenu) #residu de deviance standardises
H <- influence(modele_retenu)$hat #diagonale de la hat matrix
res_pear_stand <- res_pear/sqrt(1-H) #residu de Pearson standardises
plot(rstudent(modele_retenu), type = 'p', cex=0.5, ylab = 'Résidus studentisés par VC')
abline(h=c(-2,2))
```


Pour le modèle logistique les résidus de déviance sont souvent préférés. De nombreuses études expérimentales ont montré qu’ils approchent mieux la loi normale que les résidus de Pearson. Pour cette raison ces résidus prennent généralement des valeurs qui varient entre -2et 2.
Nous pourrons construire un index plot pour détecter des valeurs aberrantes. Ce graphique
ordonne les résidus en fonction du numéro de leur observation. Les points pour lesquels on observe
on résidu élevé (hors de [−2, 2] par exemple) devront faire l’objet d’une étude approfondie.

Dans notre cas, nous n'avons pas d'individus en-dessous de -2. Cependant, nous en avons au-dessus de 2.


<center> <h1>Distance de Cook</h1> </center>



Les points influents sont des points qui influent sur le modèle de telle sorte que si on les enlève, alors
l’estimation des coefficients sera fortement changée. La mesure la plus classique d’influence est la
distance de Cook. Il s’agit d’une distance entre le coefficient estimé avec toutes les observations et
celui estimé avec toutes les observations sauf une.

Si une distance se révèle grande par rapport aux autres, alors ce point sera considéré comme influent. Il convient alors de comprendre pourquoi il est influent. 


```{r}
infIndexPlot(modele_retenu, vars = 'Cook', id = TRUE, grid = TRUE, main = 'Les points influents')
```


Nous pouvons enlever l'individu 3972.





Cela nous a permis d'avoir un point de départ.

Pour la suite de notre travail, nous avons choisi de prendre parti sur l'hypothèse suivante :

La variable la plus significative est celle du sexe.
Donc à partir de maintenant nous allons créer 2 modèles, le premier pour les hommes et le second pour les femmes.



<center> <h1>Régression logistique modèle Femme</h1> </center>


Nous allons donc continuer par faire notre modèle de régression logistique sur les femmes, par pur galanterie.

```{r}
modelSatureFemme <- glm(estMalade10~. , data = dfApprenFemme, family = binomial)
summary(modelSatureFemme)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 5.

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


```{r}
stepAIC(modelSatureFemme)
```





La fonction stepAIC nous donne le modèle avec l'AIC le plus faible qui est le suivant :

```{r}
modelRetenuFemme <- glm(formula = estMalade10 ~ age + NbCigarrete_Jour + AVC + sysTA + 
    BPM + glucose, family = binomial, data = dfApprenFemme)
print(modelRetenuFemme)
```


```{r}
var_label(dfApprenFemme$estMalade10) <- 'Maladie dans les 10 Ans ?'
var_label(dfApprenFemme$NbCigarrete_Jour) <- 'Nombre de cigarette par jour'
var_label(dfApprenFemme$AVC) <- 'AVC'
var_label(dfApprenFemme$sysTA) <- 'Tension Artérielle Systolique'
var_label(dfApprenFemme$BPM) <- 'Fréquence Cardiaque'
var_label(dfApprenFemme$glucose) <- 'Taux de glucose'
```

Tout d'abord, nous pouvons observer que la fonction stepAIC a sélectionné 6 variables :

  - L'âge ;
  - Le nombre de cigarrette par jour ;
  - Si l'individu a eu un AVC ;
  - La tension artérielle systolique ;
  - La fréquence cardiaque ;
  - Et le taux de glucose.


Avec ce modèle nous avons un AIC de 891. 


Interprétation :

Nous avons donc un AIC de 891.
Une déviance de  877.


<center> <h1>Étude des varibles les plus influentes</h1> </center>


```{r}
exp(cbind(coef(modelRetenuFemme), confint(modelRetenuFemme)))
```


```{r}
forest_model(modelRetenuFemme)
```


```{r}
plot(ggeffect(modelRetenuFemme, "age"))
```


```{r}
plot(ggeffect(modelRetenuFemme, "NbCigarrete_Jour"))
```

```{r}
plot(ggeffect(modelRetenuFemme, "AVC"))
```

```{r}
plot(ggeffect(modelRetenuFemme, "sysTA"))
```

```{r}
plot(ggeffect(modelRetenuFemme, "BPM"))
```

```{r}
plot(ggeffect(modelRetenuFemme, "glucose"))
```


<center> <h1>Matrice de confusion</h1> </center>


```{r}
PredFemme <- predict(modelRetenuFemme, type = "response", newdata = dfTestFemme)
table(PredFemme > 0.5, dfTestFemme$estMalade10)
```

Nous avons donc 85 (82+3) prédictions incorrectes sur un total de 680, soit un taux de mauvais classement de 12.5 %.



<center> <h1>Courbe de ROC</h1> </center>



```{r}
predFemmme <- prediction(PredFemme, dfTestFemme$estMalade10)
perfFemme <- performance(predFemmme, "tpr", "fpr")
plot(perfFemme)
```


```{r}

# Analyse des résidus
res_dev <- residuals(modelRetenuFemme) #residus de deviance
res_pear <- residuals(modelRetenuFemme, type = 'pearson') #residus de Pearson
res_dev_stand <- rstandard(modelRetenuFemme) #residu de deviance standardises
H <- influence(modelRetenuFemme)$hat #diagonale de la hat matrix
res_pear_stand <- res_pear/sqrt(1-H) #residu de Pearson standardises
plot(rstudent(modelRetenuFemme), type = 'p', cex=0.5, ylab = 'Résidus studentisés par VC')
abline(h=c(-2,2))
```


Dans notre cas, nous n'avons pas d'individus en-dessous de -2. Cependant, nous en avons au-dessus de 2.
Nous allons regarder si des individus sont influents afin de les retirer.


<center> <h1>Distance de Cook</h1> </center>


Les points influents sont des points qui influent sur le modèle de telle sorte que si on les enlève, alors
l’estimation des coefficients sera fortement changée. La mesure la plus classique d’influence est la
distance de Cook. Il s’agit d’une distance entre le coefficient estimé avec toutes les observations et
celui estimé avec toutes les observations sauf une.

Si une distance se révèle grande par rapport aux autres, alors ce point sera considéré comme influent. Il convient alors de comprendre pourquoi il est influent. 


```{r}
infIndexPlot(modelRetenuFemme, vars = 'Cook', id = TRUE, grid = TRUE, main = 'Les points influents')
```


Nous pourons recommencer l'expérience en retirant ces 2 individus (1167 et 1890).


```{r}
dfApprenFemme <- dfApprenFemme %>% filter(glucose != 386 & sysTA != 194.0)
```



```{r}
modelSatureFemme <- glm(estMalade10~. , data = dfApprenFemme, family = binomial)
summary(modelSatureFemme)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 6. (age, NbCigarrete_Jour, AVC, sysTA, BPM, glucosel)

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


```{r}
stepAIC(modelSatureFemme)
```


La fonction stepAIC et la fonction nous donne le modèle avec l'AIC le plus faible qui est le suivant :

```{r}
modelRetenuFemme <- glm(formula = estMalade10 ~ age + NbCigarrete_Jour + AVC + sysTA + 
    BPM + glucose, family = binomial, data = dfApprenFemme)
print(modelRetenuFemme)
```

Tout d'abord, nous pouvons observer que la fonction stepAIC a sélectionné 6 variables :

  - L'âge ;
  - Le nombre de cigarrette par jour ;
  - La Tension Artérielle Systolique
  - Si l'individu a eu un AVC;
  - La fréquence cardiaque ;
  - Et le taux de glucose.


Interprétation :

Nous avons donc un AIC de 886,3 vs 891.
Une déviance de  872,3. vs 877.

Ce qui est quelque peu mieux qu'avec les 2 indivivus que nous venons de retirer.


<center> <h1>Matrice de confusion</h1> </center>


```{r}
PredFemme <- predict(modelRetenuFemme, type = "response", newdata = dfTestFemme)
table(PredFemme > 0.5, dfTestFemme$estMalade10)
```

Nous avons donc 85 (82+3) prédictions incorrectes sur un total de 680, soit un taux de mauvais classement de 12.5 %.

Nous retrouvons la même chose.








































<center> <h1>Régression logistique modèle Homme</h1> </center>


Nous allons donc continuer avec le modèle de régression logistique des hommes.

```{r}
modelSatureHomme <- glm(estMalade10~. , data = dfApprenHomme, family = binomial)
summary(modelSatureHomme)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 3. (age, 
sysTA, TauxChol)

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


```{r}
stepAIC(modelSatureHomme)
```


La fonction stepAIC et la fonction nous donne le modèle avec l'AIC le plus faible qui est le suivant :

```{r}
modelRetenuHomme <- glm(formula = estMalade10 ~ age + Fumeur + TauxChol + sysTA + 
    glucose, family = binomial, data = dfApprenHomme)
print(modelRetenuHomme)
```


```{r}
var_label(dfApprenHomme$estMalade10) <- 'Maladie dans les 10 Ans ?'
var_label(dfApprenHomme$age) <- 'Age'
var_label(dfApprenHomme$Fumeur) <- 'Fumeur'
var_label(dfApprenHomme$sysTA) <- 'Tension Artérielle Systolique'
var_label(dfApprenHomme$TauxChol) <- 'Taux de cholestérol'
var_label(dfApprenHomme$glucose) <- 'Taux de glucose'
```

Tout d'abord, nous pouvons observer que la fonction stepAIC a sélectionné 5 variables :

  - L'âge ;
  - La tension artérielle systolique ;
  - Si l'individu est fumeur ;
  - Le  taux de cholestérol ;
  - Et le taux de glucose.


Interprétation :

Nous avons donc un AIC de 941.
Une déviance de  929.3


<center> <h1>Étude des varibles les plus influentes</h1> </center>


```{r}
exp(cbind(coef(modelRetenuHomme), confint(modelRetenuHomme)))
```


```{r}
forest_model(modelRetenuHomme)
```


```{r}
plot(ggeffect(modelRetenuHomme, "age"))
```


```{r}
plot(ggeffect(modelRetenuHomme, "Fumeur"))
```

```{r}
plot(ggeffect(modelRetenuHomme, "TauxChol"))
```

```{r}
plot(ggeffect(modelRetenuHomme, "sysTA"))
```

```{r}
plot(ggeffect(modelRetenuHomme, "glucose"))
```


<center> <h1>Matrice de confusion</h1> </center>


```{r}
PredHomme <- predict(modelRetenuHomme, type = "response", newdata = dfTestHomme)
table(PredHomme > 0.5, dfTestHomme$estMalade10)
```

Nous avons donc 104 (91+13) prédictions incorrectes sur un total de 544, soit un taux de mauvais classement de 19.1 %.



<center> <h1>Courbe de ROC</h1> </center>



```{r}
ROCHommme <- prediction(PredHomme, dfTestHomme$estMalade10)
perfHomme <- performance(ROCHommme, "tpr", "fpr")
plot(perfHomme)
```


```{r}
# Analyse des résidus
res_dev <- residuals(modelRetenuHomme) #residus de deviance
res_pear <- residuals(modelRetenuHomme, type = 'pearson') #residus de Pearson
res_dev_stand <- rstandard(modelRetenuHomme) #residu de deviance standardises
H <- influence(modelRetenuHomme)$hat #diagonale de la hat matrix
res_pear_stand <- res_pear/sqrt(1-H) #residu de Pearson standardises
plot(rstudent(modelRetenuHomme), type = 'p', cex=0.5, ylab = 'Résidus studentisés par VC')
abline(h=c(-2,2))
```


Dans notre cas, nous n'avons pas d'individus en-dessous de -2. Cependant, nous en avons au-dessus de 2.
Nous allons regarder si des individus sont influents afin de les retirer.


<center> <h1>Distance de Cook</h1> </center>


Les points influents sont des points qui influent sur le modèle de telle sorte que si on les enlève, alors
l’estimation des coefficients sera fortement changée. La mesure la plus classique d’influence est la
distance de Cook. Il s’agit d’une distance entre le coefficient estimé avec toutes les observations et
celui estimé avec toutes les observations sauf une.

Si une distance se révèle grande par rapport aux autres, alors ce point sera considéré comme influent. Il convient alors de comprendre pourquoi il est influent. 


```{r}
infIndexPlot(modelRetenuHomme, vars = 'Cook', id = TRUE, grid = TRUE, main = 'Les points influents')
```


Nous pourons recommencer l'expérience en retirant l'individus 1503.


```{r}
dfApprenHomme <- dfApprenHomme %>% filter(glucose != 370)
```



```{r}
modelSatureHomme <- glm(estMalade10~. , data = dfApprenHomme, family = binomial)
summary(modelSatureHomme)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 3. (age, 
sysTA, TauxChol)

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


```{r}
stepAIC(modelSatureHomme)
```


La fonction stepAIC et la fonction nous donne le modèle avec l'AIC le plus faible qui est le suivant :

```{r}
modelRetenuHomme <- glm(formula = estMalade10 ~ age + Fumeur + TauxChol + sysTA + 
    glucose, family = binomial, data = dfApprenHomme)
print(modelRetenuHomme)
```

Tout d'abord, nous pouvons observer que la fonction stepAIC a sélectionné 5 variables :

  - L'âge ;
  - La tension artérielle systolique ;
  - Si l'individu est fumeur ;
  - Le  taux de cholestérol ;
  - Et le taux de glucose.


Interprétation :

Nous avons donc un AIC de 941.
Une déviance de  929.3


<center> <h1>Matrice de confusion</h1> </center>


```{r}
PredHomme <- predict(modelRetenuHomme, type = "response", newdata = dfTestHomme)
table(PredHomme > 0.5, dfTestHomme$estMalade10)
```

Nous avons donc 104 (91+13) prédictions incorrectes sur un total de 544, soit un taux de mauvais classement de 19.1 %.

Nous retrouvons la même chose.

Il est probable que cela soit dû à un manque de donnée sur les hommes.