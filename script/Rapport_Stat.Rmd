---
output: html_document
runtime: shiny
---

<div>
<img src="https://media.licdn.com/dms/image/C560BAQHUCPLKiBDG3w/company-logo_200_200/0?e=2159024400&v=beta&t=oyn1hcdUk9NXqcdZgb_kIhABmIAiniK5pE4onmVdhFM" width=18%" align="left"/>

<img src="https://www.businessdecision.fr/uploads/Image/b8/IMF_ACCROCHE/GAB_BDFRANCE/8178_919_Keyviz-carre.jpg" width=20% align="right" />
</div>
<br /><br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
\n<br />
<div>
<center> <h1>Master2 MEDAS - USID17 - Statistiques - Faits stylisés du hasard</h1> </center>
</div>

\n<br />
\n<br />

<div align="center">
<img src="https://mrmint.fr/wp-content/uploads/2017/09/logistic-regression-model.png" width=50%/>
</div>

\n<br />
\n<br />

<center>**Groupe :** É.Guilmin & M.Chauveau </center>

\n<br />
\n<br />

<center>**Jury :** Erwan Josse </center>

<center>**Responsable Pédagogique :** X.Aimé  </center>

\n<br />
\n<br />

<center>**Établissement :** Cnam - Pays de la Loire - Nantes </center>

<center>**Formation :** Master Mégadonnées et Analyse Sociale </center>

\n<br />
\n<br />

```{r setup, include=FALSE}
#install.packages('pacman')

pacman::p_load('tidyr')
pacman::p_load('dplyr')

#ggplot pour les représentations graphiques
pacman::p_load('ggplot2')
pacman::p_load('plotly')

# MASS pour la fonction stepAIC
pacman::p_load('MASS')

#
pacman::p_load('questionr')

# pour fonction sample.split
pacman::p_load('caTools')

pacman::p_load('knitr')

#Matrice de corrélation
pacman::p_load('corrplot')

#Représentation graphique du modèle
pacman::p_load('forestmodel')

#Représentation graphique des effets
pacman::p_load('labelled')
pacman::p_load('ggeffects')
pacman::p_load('cowplot')
pacman::p_load('effects')

# Courbe ROC
pacman::p_load('ROCR')

#Distance de Cook
pacman::p_load('car')
```


```{r chargement des données}
load(file='C:/Users/mchauveau/Documents/Maxime Chauveau/Master Medas/Projet_Stat/data/dataClean.RData')
```


\n<br />
\n<br />

<center> <h1>Présentation du sujet</h1> </center>

\n<br />
\n<br />


Pour ce projet, nous avons choisi le sujet suivant : Prédiction des maladies cardiaques.

https://www.kaggle.com/dileep070/heart-disease-prediction-using-logistic-regression

Pour ce faire, nous avons préalablement préparé nos données, le scritp est disponible ici : ./script/data_prep.R

Ici nous verrons notre méthodologie de travail. 


<center> <h1>Statistique bivarivée</h1> </center>

Afin de mieux comprendre notre base de données, nous avons décidé de faire une étude descriptive.


```{r}
freq(df_heart$estMalade10)
```

Notre base comporte 3656 patients, dans laquelle 15 % des patients ont eu une maladie cardiovasculaire dans les 10 années suivants les prises de mesures. Ces données proviennt de la ville de Framingham dans le Massachusetts, aux États-Unis.

```{r}

fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$BPM[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$BPM[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par Sexe}

fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$Sexe[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$Sexe[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par Education}

fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$education[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$education[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r}

fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$Fumeur[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$Fumeur[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par NbCigarrette_Jour faire des classes}

fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$NbCigarrete_Jour[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$NbCigarrete_Jour[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par MedPA}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$MedPA[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$MedPA[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par AVC}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$AVC[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$AVC[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par Hypertension}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$Hypertension[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$Hypertension[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par diabetes}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$diabetes[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$diabetes[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par TauxChol}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$TauxChol[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$TauxChol[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par sysTA}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$sysTA[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$sysTA[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```



```{r Analyse par diaTA}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$diaTA[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$diaTA[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par IMC}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$IMC[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$IMC[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par BPM}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$BPM[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$BPM[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


```{r Analyse par glucose}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$glucose[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$glucose[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```

```{r Analyse par age}
fig <- plot_ly(alpha = 0.6)
fig <- fig %>% add_histogram(x = df_heart$age[df_heart$estMalade10 == 0], name = 'Pas malade')
fig <- fig %>% add_histogram(x = df_heart$age[df_heart$estMalade10 == 1], name = 'Malade')
fig <- fig %>% layout(barmode = "overlay")

fig
```


<center> <h1>Matrice de corrélation</h1> </center>

```{r}
mcor <- cor(df_correlation)
corrplot(mcor, type="upper", order="hclust", tl.col="black", tl.srt=45)
```

Les variables Fumeur et nbcigarrete_Jour sont très correlées : 0.77
diabetes glucose : 0.61
sysTA et diaTA : 0.79
Hypertention et sysTA : 0.70
Hypertension et diaTA : 0.62


<center> <h1>Régression logistique</h1> </center>


L'objectif de la régression logistique est de modéliser, de classifier, une variable binaire prenant ses valeurs dans {0,1} en fonction de variables explicatives quantitatives (et potentiellement qualitatives). La régression logistique est une méthode de classification (supervisée) qui permet de traiter des cas comme :

  - la prévision de présence/absence d'une maladie ;

  - la prévision de l'état de fonctionnement d'une machine-outil en fonction de ses caractéristiques (ancienneté, modèle, etc.), à des fins de maintenance prédictive ;

  - le credit scoring (attribution ou non d'un crédit).


Pour commencer nous allons faire une régression directement sur notre base de données.


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 6.

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


Une alternative à la fonction stepAIC est la fonction step qui fonctionne de la même manière. Cependant cela ne change rien aux régressions logistiques classiques.





Avec ce modèle nous avons un AIC de 2775. Pour rappel, l'AIC est le critère d'information d'Akaike, (en anglais Akaike information criterion ou AIC). C'est une mesure de la qualité d'un modèle statistique proposée par Hirotugu Akaike en 1973.

Lorsque l'on estime un modèle statistique, il est possible d'augmenter la vraisemblance du modèle en ajoutant un paramètre. Le critère d'information d'Akaike, tout comme le critère d'information bayésien, permet de pénaliser les modèles en fonction du nombre de paramètres afin de satisfaire le critère de parcimonie. On choisit alors le modèle avec le critère d'information d'Akaike le plus faible.


Interprétation

Nous avons donc un AIC de 2775.
Une déviance de  2757.

Elle compare la vraisemblance obtenue à celle d’un modèle de référence : le modèle complet (ou modèle saturé).












<center> <h1>Régression logistique modèle équilibré</h1> </center>


Nous allons donc continuer par faire notre modèle de régression logistique sur un modèle équilibré, c'est à dire 50% de malade et 50% de non malade.

Nous ferons notre prédiction sur une base test représentative dans la population initiale.


```{r}
modelSatureEqui <- glm(estMalade10~. , data = dfApprenEqui, family = binomial)
summary(modelSatureEqui)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 8.

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


```{r}
stepAIC(modelSatureEqui)
```



La fonction stepAIC nous donne le modèle avec l'AIC le plus faible qui est le suivant :

```{r}
modelRetenuEqui <- glm(formula = estMalade10 ~ Sexe + AVC + Hypertension + agelabel + CigaretteLabels + glucoseLabels, family = binomial, data = dfApprenEqui)
print(modelRetenuEqui)
```


```{r}
var_label(dfApprenFemme$estMalade10) <- 'Maladie dans les 10 Ans ?'
var_label(dfApprenFemme$NbCigarrete_Jour) <- 'Nombre de cigarette par jour'
var_label(dfApprenFemme$AVC) <- 'AVC'
var_label(dfApprenFemme$sysTA) <- 'Tension Artérielle Systolique'
var_label(dfApprenFemme$BPM) <- 'Fréquence Cardiaque'
var_label(dfApprenFemme$glucose) <- 'Taux de glucose'
```

Tout d'abord, nous pouvons observer que la fonction stepAIC a retenu 8 variables pour le modèle :

  - Le sexe ;
  - L'âge ;
  - Le niveau d'éducation ;
  - Le nombre de cigarrette par jour ;
  - Si l'individu a fait de l'hypertension;
  - La tension artérielle systolique ;
  - L'IMC ;
  - Et le taux de glucose.


Avec ce modèle nous avons un AIC de 1360.


Interprétation :

Nous avons donc un AIC de 1360.
Une déviance de  1338.


<center> <h1>Étude des varibles les plus influentes</h1> </center>


```{r}
forest_model(modelRetenuEqui)
```


```{r}
plot(ggeffect(modelRetenuEqui, "age"))
```


```{r}
plot(ggeffect(modelRetenuEqui, "NbCigarrete_Jour"))
```

```{r}
plot(ggeffect(modelRetenuEqui, "IMC"))
```

```{r}
plot(ggeffect(modelRetenuEqui, "sysTA"))
```

```{r}
plot(ggeffect(modelRetenuEqui, "education"))
```

```{r}
plot(ggeffect(modelRetenuEqui, "Hypertension"))
```

```{r}
plot(ggeffect(modelRetenuEqui, "Sexe"))
```

```{r}
plot(ggeffect(modelRetenuEqui, "glucose"))
```


<center> <h1>Matrice de confusion</h1> </center>


```{r}
PreEqui <- predict(modelRetenuEqui, type = "response", newdata = dfTestEqui)
table(PreEqui > 0.5, dfTestEqui$estMalade10)
```

Nous avons donc 2341,, (1940+401) prédictions incorrectes sur un total de 3656, soit un bon taux de prédiction de 64.03 %.

Cependant, sur les 557, (156+401) patients qui vont avoir une maladie cardiaque dans les 10 prochaines années, notre modèle en prédit 401 soit un taux de bonne prédiction de 71.99 %.


<center> <h1>Courbe de ROC</h1> </center>



```{r}
Equi <- prediction(PreEqui, dfTestEqui$estMalade10)
perfEqui <- performance(Equi, "tpr", "fpr")
plot(perfEqui)
```


```{r}

# Analyse des résidus
res_dev <- residuals(modelRetenuEqui) #residus de deviance
res_pear <- residuals(modelRetenuEqui, type = 'pearson') #residus de Pearson
res_dev_stand <- rstandard(modelRetenuEqui) #residu de deviance standardises
H <- influence(modelRetenuEqui)$hat #diagonale de la hat matrix
res_pear_stand <- res_pear/sqrt(1-H) #residu de Pearson standardises
plot(rstudent(modelRetenuEqui), type = 'p', cex=0.5, ylab = 'Résidus studentisés par VC')
abline(h=c(-2,2))
```


Dans notre cas, nous n'avons pas d'individus en-dessous de -2. Cependant, nous en avons au-dessus de 2.
Nous allons regarder si des individus sont influents afin de les retirer.


<center> <h1>Distance de Cook</h1> </center>


Les points influents sont des points qui influent sur le modèle de telle sorte que si on les enlève, alors
l’estimation des coefficients sera fortement changée. La mesure la plus classique d’influence est la
distance de Cook. Il s’agit d’une distance entre le coefficient estimé avec toutes les observations et
celui estimé avec toutes les observations sauf une.

Si une distance se révèle grande par rapport aux autres, alors ce point sera considéré comme influent. Il convient alors de comprendre pourquoi il est influent. 


```{r}
infIndexPlot(modelRetenuEqui, vars = 'Cook', id = TRUE, grid = TRUE, main = 'Les points influents')
```


Nous pourons recommencer l'expérience en retirant ces 2 individus (586 et 656).


```{r}
dfApprenEqui <- dfApprenEqui[-c(709, 813),]
```



```{r}
modelSaturEqui2 <- glm(estMalade10~. , data = dfApprenEqui, family = binomial)
summary(modelSaturEqui2)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 3. (age, 
sysTA, TauxChol)

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


```{r}
stepAIC(modelSaturEqui2)
```


La fonction stepAIC et la fonction nous donne le modèle avec l'AIC le plus faible qui est le suivant :

```{r}
modelRetenuEqui2 <- glm(formula = estMalade10 ~ Sexe + Hypertension + diabetes + agelabel + CigaretteLabels + diaTALabels, family = binomial, data = dfApprenEqui)
print(modelRetenuEqui2)
```

Tout d'abord, nous pouvons observer que la fonction stepAIC a sélectionné 5 variables :

  - L'âge ;
  - La tension artérielle systolique ;
  - Si l'individu est fumeur ;
  - Le  taux de cholestérol ;
  - Et le taux de glucose.


Interprétation :

Nous avons donc un AIC de 941.
Une déviance de  929.3


<center> <h1>Matrice de confusion</h1> </center>


```{r}
PredEqui2 <- predict(modelRetenuEqui2, type = "response", newdata = dfTestEqui)
table(PredEqui2 > 0.5, dfTestEqui$estMalade10)
```

Nous avons donc 2358 (1962+396) prédictions correctes sur un total de 3656, soit un bon taux de prédiction de 64.50 %.

Cependant, sur -557, (161+396) patients qui vont avoir une maladie cardiaque dans les 10 prochaines années, notre modèle en prédit 110 soit un bon taux de prédiction de 71.10 %.

























<center> <h1>Régression logistique modèle équilibré des hommes</h1> </center>


Nous allons donc continuer par faire notre modèle de régression logistique sur un modèle équilibré, c'est à dire 50% de malade et 50% de non malade, pour les hommes

Nous ferons notre prédiction sur une base test représentative dans la population initiale.


```{r}
modelSaturEquiHomme <- glm(estMalade10~. , data = dfApprenEquiHomme, family = binomial)
summary(modelSaturEquiHomme)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 8.

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


```{r}
stepAIC(modelSaturEquiHomme)
```



La fonction stepAIC nous donne le modèle avec l'AIC le plus faible qui est le suivant :

```{r}
modelRetenuEquiHomme <- glm(formula = estMalade10 ~ MedPA + diabetes + agelabel + CigaretteLabels + 
    diaTALabels + TauxCholLabels, family = binomial, data = dfApprenEquiHomme)
print(modelRetenuEquiHomme)
```


```{r}
var_label(dfApprenFemme$estMalade10) <- 'Maladie dans les 10 Ans ?'
var_label(dfApprenFemme$NbCigarrete_Jour) <- 'Nombre de cigarette par jour'
var_label(dfApprenFemme$AVC) <- 'AVC'
var_label(dfApprenFemme$sysTA) <- 'Tension Artérielle Systolique'
var_label(dfApprenFemme$BPM) <- 'Fréquence Cardiaque'
var_label(dfApprenFemme$glucose) <- 'Taux de glucose'
```

Tout d'abord, nous pouvons observer que la fonction stepAIC a retenu 8 variables pour le modèle :

  - Le sexe ;
  - L'âge ;
  - Le niveau d'éducation ;
  - Le nombre de cigarrette par jour ;
  - Si l'individu a fait de l'hypertension;
  - La tension artérielle systolique ;
  - L'IMC ;
  - Et le taux de glucose.


Avec ce modèle nous avons un AIC de 1360.


Interprétation :

Nous avons donc un AIC de 1360.
Une déviance de  1338.


<center> <h1>Étude des varibles les plus influentes</h1> </center>


```{r}
forest_model(modelRetenuEquiHomme)
```


```{r}
plot(ggeffect(modelRetenuEquiHomme, "age"))
```


```{r}
plot(ggeffect(modelRetenuEquiHomme, "NbCigarrete_Jour"))
```

```{r}
plot(ggeffect(modelRetenuEquiHomme, "IMC"))
```

```{r}
plot(ggeffect(modelRetenuEquiHomme, "sysTA"))
```

```{r}
plot(ggeffect(modelRetenuEquiHomme, "education"))
```

```{r}
plot(ggeffect(modelRetenuEquiHomme, "Hypertension"))
```

```{r}
plot(ggeffect(modelRetenuEquiHomme, "Sexe"))
```

```{r}
plot(ggeffect(modelRetenuEquiHomme, "glucose"))
```


<center> <h1>Matrice de confusion</h1> </center>


```{r}
PreEquiHomme <- predict(modelRetenuEquiHomme, type = 'response', newdata = dfTestEquiHomme)
table(PreEquiHomme > 0.5, dfTestEquiHomme$estMalade10)
```


Nous avons donc 1039 (824+215) prédictions incorrectes sur un total de 1622, soit un bon taux de prédiction de 64.06 %.

Cependant, sur 307 (92+215) patients qui vont avoir une maladie cardiaque dans les 10 prochaines années, notre modèle en prédit 215 soit un taux de bonne prédiction de 70.03% %.


<center> <h1>Courbe de ROC</h1> </center>



```{r}
EquiHomme <- prediction(PreEquiHomme, dfTestEquiHomme$estMalade10)
perfEquiHomme <- performance(EquiHomme, "tpr", "fpr")
plot(perfEquiHomme)
```


```{r}
# Analyse des résidus
res_dev <- residuals(modelRetenuEquiHomme) #residus de deviance
res_pear <- residuals(modelRetenuEquiHomme, type = 'pearson') #residus de Pearson
res_dev_stand <- rstandard(modelRetenuEquiHomme) #residu de deviance standardises
H <- influence(modelRetenuEquiHomme)$hat #diagonale de la hat matrix
res_pear_stand <- res_pear/sqrt(1-H) #residu de Pearson standardises
plot(rstudent(modelRetenuEquiHomme), type = 'p', cex=0.5, ylab = 'Résidus studentisés par VC')
abline(h=c(-2,2))
```


Dans notre cas, nous n'avons pas d'individus en-dessous de -2. Cependant, nous en avons au-dessus de 2.
Nous allons regarder si des individus sont influents afin de les retirer.


<center> <h1>Distance de Cook</h1> </center>


Les points influents sont des points qui influent sur le modèle de telle sorte que si on les enlève, alors
l’estimation des coefficients sera fortement changée. La mesure la plus classique d’influence est la
distance de Cook. Il s’agit d’une distance entre le coefficient estimé avec toutes les observations et
celui estimé avec toutes les observations sauf une.

Si une distance se révèle grande par rapport aux autres, alors ce point sera considéré comme influent. Il convient alors de comprendre pourquoi il est influent. 


```{r}
infIndexPlot(modelRetenuEquiHomme, vars = 'Cook', id = TRUE, grid = TRUE, main = 'Les points influents')
```


Nous pourons recommencer l'expérience en retirant cet individu (574).


```{r}
dfApprenEquiHomme <- dfApprenEquiHomme[-574,]
```



```{r}
modelSaturEquiHomme2 <- glm(estMalade10~. , data = dfApprenEquiHomme, family = binomial)
summary(modelSaturEquiHomme2)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 3. (age, 
sysTA, TauxChol)

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


```{r}
stepAIC(modelSaturEquiHomme2)
```


La fonction stepAIC et la fonction nous donne le modèle avec l'AIC le plus faible qui est le suivant :

```{r}
modelRetenuEquiHomme2 <- glm(formula = estMalade10 ~ MedPA + diabetes + agelabel + CigaretteLabels + 
    diaTALabels + TauxCholLabels, family = binomial, data = dfApprenEquiHomme)
print(modelRetenuEquiHomme2)
```

Tout d'abord, nous pouvons observer que la fonction stepAIC a sélectionné 5 variables :

  - L'âge ;
  - La tension artérielle systolique ;
  - Si l'individu est fumeur ;
  - Le  taux de cholestérol ;
  - Et le taux de glucose.


Interprétation :

Nous avons donc un AIC de 941.
Une déviance de  929.3


<center> <h1>Matrice de confusion</h1> </center>


```{r}
PredEquiHomme2 <- predict(modelRetenuEquiHomme2, type = "response", newdata = dfTestEquiHomme)
table(PredEquiHomme2 > 0.5, dfTestEquiHomme$estMalade10)
```

Nous avons donc 1039 (824+215) prédictions incorrectes sur un total de 1622, soit un bon taux de prédiction de 64.06 %.

Cependant, sur 307 patients qui vont avoir une maladie cardiaque dans les 10 prochaines années, notre modèle en prédit 215 soit un bon taux de prédiction de 70.03 %.























<center> <h1>Régression logistique modèle équilibré des femmes</h1> </center>


Nous allons donc continuer par faire notre modèle de régression logistique sur un modèle équilibré, c'est à dire 50% de malade et 50% de non malade, pour les femmes

Nous ferons notre prédiction sur une base test représentative dans la population initiale.


```{r}
modelSaturEquiFemme <- glm(estMalade10~. , data = dfApprenEquiFemme, family = binomial)
summary(modelSaturEquiFemme)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 8.

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


```{r}
stepAIC(modelSaturEquiFemme)
```



La fonction stepAIC nous donne le modèle avec l'AIC le plus faible qui est le suivant :

```{r}
modelRetenuEquiFemme <- glm(formula = estMalade10 ~ AVC + Hypertension + agelabel + CigaretteLabels + 
    BPMLabels, family = binomial, data = dfApprenEquiFemme)
print(modelRetenuEquiFemme)
```


```{r}
var_label(dfApprenFemme$estMalade10) <- 'Maladie dans les 10 Ans ?'
var_label(dfApprenFemme$NbCigarrete_Jour) <- 'Nombre de cigarette par jour'
var_label(dfApprenFemme$AVC) <- 'AVC'
var_label(dfApprenFemme$sysTA) <- 'Tension Artérielle Systolique'
var_label(dfApprenFemme$BPM) <- 'Fréquence Cardiaque'
var_label(dfApprenFemme$glucose) <- 'Taux de glucose'
```

Tout d'abord, nous pouvons observer que la fonction stepAIC a retenu 8 variables pour le modèle :

  - Le sexe ;
  - L'âge ;
  - Le niveau d'éducation ;
  - Le nombre de cigarrette par jour ;
  - Si l'individu a fait de l'hypertension;
  - La tension artérielle systolique ;
  - L'IMC ;
  - Et le taux de glucose.


Avec ce modèle nous avons un AIC de 1360.


Interprétation :

Nous avons donc un AIC de 1360.
Une déviance de  1338.


<center> <h1>Étude des varibles les plus influentes</h1> </center>


```{r}
forest_model(modelRetenuEquiFemme)
```


```{r}
plot(ggeffect(modelRetenuEquiFemme, "age"))
```


```{r}
plot(ggeffect(modelRetenuEquiFemme, "NbCigarrete_Jour"))
```

```{r}
plot(ggeffect(modelRetenuEquiFemme, "IMC"))
```

```{r}
plot(ggeffect(modelRetenuEquiFemme, "sysTA"))
```

```{r}
plot(ggeffect(modelRetenuEquiFemme, "education"))
```

```{r}
plot(ggeffect(modelRetenuEquiFemme, "Hypertension"))
```

```{r}
plot(ggeffect(modelRetenuEquiFemme, "Sexe"))
```

```{r}
plot(ggeffect(modelRetenuEquiFemme, "glucose"))
```


<center> <h1>Matrice de confusion</h1> </center>


```{r}
PreEquiFemme <- predict(modelRetenuEquiFemme, type = "response", newdata = dfTestEquiFemme)
table(PreEquiFemme > 0.5, dfTestEquiFemme$estMalade10)
```


Nous avons donc 1387, (1124+179) prédictions correctes sur un total de 2034, soit un bon taux de prédiction de 64.06 %.

Cependant, sur 250 patients qui vont avoir une maladie cardiaque dans les 10 prochaines années, notre modèle en prédit 179 soit un bon taux de prédiction de 71.60 %.


<center> <h1>Courbe de ROC</h1> </center>



```{r}
EquiFemme <- prediction(PreEquiFemme, dfTestEquiFemme$estMalade10)
perfEquiFemme <- performance(EquiFemme, "tpr", "fpr")
plot(perfEquiFemme)
```


```{r}
# Analyse des résidus
res_dev <- residuals(modelRetenuEquiFemme) #residus de deviance
res_pear <- residuals(modelRetenuEquiFemme, type = 'pearson') #residus de Pearson
res_dev_stand <- rstandard(modelRetenuEquiFemme) #residu de deviance standardises
H <- influence(modelRetenuEquiFemme)$hat #diagonale de la hat matrix
res_pear_stand <- res_pear/sqrt(1-H) #residu de Pearson standardises
plot(rstudent(modelRetenuEquiFemme), type = 'p', cex=0.5, ylab = 'Résidus studentisés par VC')
abline(h=c(-2,2))
```


Dans notre cas, nous n'avons pas d'individus en-dessous de -2. Cependant, nous en avons au-dessus de 2.
Nous allons regarder si des individus sont influents afin de les retirer.


<center> <h1>Distance de Cook</h1> </center>


Les points influents sont des points qui influent sur le modèle de telle sorte que si on les enlève, alors
l’estimation des coefficients sera fortement changée. La mesure la plus classique d’influence est la
distance de Cook. Il s’agit d’une distance entre le coefficient estimé avec toutes les observations et
celui estimé avec toutes les observations sauf une.

Si une distance se révèle grande par rapport aux autres, alors ce point sera considéré comme influent. Il convient alors de comprendre pourquoi il est influent. 


```{r}
infIndexPlot(modelRetenuEquiFemme, vars = 'Cook', id = TRUE, grid = TRUE, main = 'Les points influents')
```


Nous pourons recommencer l'expérience en retirant ces 2 individus (429 et 462).


```{r}
dfApprenEquiFemme <- dfApprenEquiFemme[-c(429, 462),]
```



```{r}
modelSaturEquiFemme2 <- glm(estMalade10~. , data = dfApprenEquiFemme, family = binomial)
summary(modelSaturEquiFemme2)
```


La première analyse que nous pouvons avec cette régression est que certaines des variables obtenues ont des p-valeurs qui sont inférieures au niveau de test de 5 %, ce qui nous indique qu'elles sont bien significatives. Certaines autres ne sont pas en dessous de ce seuil. Nous pouvons en lister 3. (age, 
sysTA, TauxChol)

On peut donc passer sur une procédure de sélection en retirant les variables non significatives au fur et à mesure, mais nous pouvons aussi sélectionner automatiquement un modèle avec une commande telle que stepAIC  , qui sélectionne de manière automatique un modèle en se basant sur le critère AIC.


```{r}
stepAIC(modelSaturEquiFemme2)
```


La fonction stepAIC et la fonction nous donne le modèle avec l'AIC le plus faible qui est le suivant :

```{r}
modelRetenuEquiFemme2 <- glm(formula = estMalade10 ~ age + NbCigarrete_Jour + Hypertension + sysTA + glucose, family = binomial, data = dfApprenEquiFemme)
print(modelRetenuEquiFemme2)
```

Tout d'abord, nous pouvons observer que la fonction stepAIC a sélectionné 5 variables :

  - L'âge ;
  - La tension artérielle systolique ;
  - Si l'individu est fumeur ;
  - Le  taux de cholestérol ;
  - Et le taux de glucose.


Interprétation :

Nous avons donc un AIC de 941.
Une déviance de  929.3


<center> <h1>Matrice de confusion</h1> </center>


```{r}
PredEquiFemme2 <- predict(modelRetenuEquiFemme2, type = "response", newdata = dfTestEquiFemme)
table(PredEquiFemme2 > 0.5, dfTestEquiFemme$estMalade10)
```

Nous avons donc 1378, (1216+162) prédictions correctes sur un total de 2034, soit un bon taux de prédiction de 67.75 %.

Cependant, sur 250 patients qui vont avoir une maladie cardiaque dans les 10 prochaines années, notre modèle en prédit 162 soit un taux de bonne prédiction de 64.8,0 %.
